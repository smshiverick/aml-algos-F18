# PROJECT CLASSIFICATION MODELS with MULTIPLE COVARIATES 
## Predictive Models of Pain Reliever Misuse and Abuse
### S. M. Shiverick        Fall, 2018
==============================================

## A. Data Preparation and Preprocessing
* Load combined dataset from NSDUH-2015-16
* Remove variables PRLMISAB HEROINEVR

```{r}
library(caret); library(ggplot2)
opioids = read.csv("project-data-2018.csv")
dim(opioids)
names(opioids)

opioids = opioids[,-c(10,11,12,18)]
names(opioids)
```

# (b) Explore data to examine associations between mpg01 and other features
# graphically with scatterplots and boxplots; Which features likely predict mpg01? 

```{r}
pairs(~AGECAT + EDUCAT + HEALTH + TRTMENT, opioids, col=opioids$AGECAT)
```

# Produce side by side boxplots in Quad plot
```{r}
par(mfrow=c(2,2))
boxplot(CTYMETRO~PRLMISEVR, data=opioids, xlab="Pain Reliever Misuse", ylab="CTYMETRO")
boxplot(HEALTH~PRLMISEVR, data=opioids, xlab="Pain Reliever Misuse", ylab="Health Problems")
boxplot(MENTHLTH~PRLMISEVR, data=opioids, xlab="Pain Reliever Misuse", ylab="Mental Healt")
boxplot(TRQLZRS~PRLMISEVR, data=opioids, xlab="Pain Reliever Misuse", ylab="Tranquilizer Use")
```
# reset plot frame  
```{r}
par(mfrow=c(1,1))
```


## Model 1.A Fit LOGISTIC REGRESSION model to Full Dataset
* Fit Logistic Regression with all variables, PRLMISEVR as response

```{r}
attach(opioids)
glm.fit1=glm(PRLMISEVR ~.-MHTRTMT, data=opioids, family=binomial)
summary(glm.fit1)
```

# 1(b) Make Predictions from the fitted model (glm.fit)
```{r}
glm.probs = predict(glm.fit1, type="response")
glm.probs[1:10]
```

# 1(c) Get confusion matrix of Predicted and Actual Values 
* Returns overall fraction of correct predictions

```{r}
glm.pred = rep("No", 114038)
glm.pred[glm.probs>0.5]="Yes"
table(glm.pred, PRLMISEVR)
```

# 1(d) Calculate accuracy and mean classification performance
* 90.8% Model accuracy for entire dataset
```{r}
(100482+2579)/114038
```

# 1(e) Fit Logistic Regression model to the TRAINING set (N=91230)
* Divide the dataset into TRAINING and TEST sets

```{r}
smp_size <- floor(.8 * nrow(opioids))
tr <- sample(seq_len(nrow(opioids)),size=smp_size)

train.opd <- opioids[tr,]
test.opd <- opioids[-tr,]

dim(train.opd); dim(test.opd)
```

```{r}
glm.fit2 = glm(PRLMISEVR ~.-MHTRTMT, data=train.opd,family=binomial)
glm.probs = predict(glm.fit2, test.opd, type="response")
length(glm.probs)
```

# 1(f) Obtain Confusion matrix of correct predictions for TEST set 
```{r}
glm.pred = rep("No", 22808)
glm.pred[glm.probs>0.5]="Yes"
length(glm.pred)

table(glm.pred, test.opd$PRLMISEVR)

#mean(glm.pred==train.opd$PRLMISEVR)
```

# 1(g) Calculate classification performance and model accuracy for TEST set
* 91.1% Model accuracy for TEST set
```{r}
(20045+ 504)/22808
```


# Model 2. LINEAR DISCRIMINANT ANALYSIS (LDA)
* Fit model to TRAIN set
```{r}
library(MASS)
lda.fit = lda(PRLMISEVR ~ .-MHTRTMT, data=train.opd, family=binomial)
lda.fit
```

# Run lda model on TEST subset of Weekly data, call predict on LDA
```{r}
lda.pred = predict(lda.fit, test.opd)
data.frame(lda.pred)[1:5,]
```

# Table of prediction versus True Direction and mean correct predictions
```{r}
table(lda.pred$class, test.opd$PRLMISEVR)
mean(lda.pred$class==test.opd$PRLMISEVR)

(19735+728) / 22808
```


# (f) QUADRATIC DISCRIMINANT ANALYSIS (QDA)
* Firt QDA model on TRAIN set
```{r}
qda.fit = qda(PRLMISEVR ~ .-MHTRTMT, data=train.opd, family=binomial)
qda.fit
```

# Run lda model on TEST subset of Weekly data, call predict on LDA
```{r}
qda.pred = predict(qda.fit, test.opd)
data.frame(qda.pred)[1:5,]
```

# Table of prediction versus True Direction and mean correct predictions
```{r}
table(qda.pred$class, test.opd$PRLMISEVR)
mean(qda.pred$class == test.opd$PRLMISEVR)

(18712+1039)/22808
```



# MODEL 4: DECISION TREE CLASSIFICATION
* Split data set into TRAIN and TEST sets
```{r}
library(tree); library(caret);
#library(rpart); library(rpart.plot)

smp_size <- floor(.8 * nrow(opioids))
tr <- sample(seq_len(nrow(opioids)),size=smp_size)

train.opd <- opioids[tr,]
test.opd <- opioids[-tr,]

dim(train.opd); dim(test.opd)
```

# Create a decision tree model using the t
fit1 <- tree(as.factor(target) ~ ., data=strain)
plot(fit1)
title(main="tree")
text(fit1)
```{r}
fitTree = tree(as.factor(PRLMISEVR) ~ . -MHTRTMT, data=train.opd, method = "class")
summary(fitTree)
plot(fitTree); text(fitTree, pretty=0.25)

```

# Fit Tree Classifier to the holdout TRAIN data
```{r}
fitTree.pred <- predict(fitTree, newdata=test.opd, type="class")
table(fitTree.pred,test.opd$PRLMISEVR)
```

#  For detailed summary of the tree, print it:

```{r}
#rpart.plot(tree.opd); text(tree.opd, pretty=0.25)
#tree.opd
```

# Evaluate performance fo the Classifier tree on the TEST data 
* Create prediction table and mean performance for TEST subset

```{r} 
treeFit <- tree(as.factor(PRLMISEVR) ~ . -MHTRTMT, train.opd)
treeFit.pred <- predict(treeFit, newdata=test.opd, type='class')
table(treeFit.pred, test.opd$PRLMISEVR)
```







# Model 4. FITTING REGRESSION TREES
* Load tree library for regression trees
* Remove SUICATT and PRLANY from dataset
* Create training set based on 70/30 split
* Fit tree to training data, summarize and plot it. 

```{r}
library(tree)
set.seed(2)
dim(opioids)
opioid = opioids[,-c(9,11)]
names(opioid)

train = sample(1:nrow(opioid), 40000)


tree.opioid = tree(PRLMISAB~., data=opioid, subset=train)
summary(tree.opioid)

plot(tree.opioid)
text(tree.opioid, pretty=0.25)
```

## Use cross-validation to determine optimal tree complexity. 
* Does pruning the tree improve the test MSE?

```{r}
cv.opioid = cv.tree(tree.opioid)
plot(cv.opioid$size, cv.opioid$dev, type='b')

prune.opioid = prune.tree(tree.opioid, best=5)
plot(prune.opioid)
text(prune.opioid, pretty=0)
```

## Evaluate tree model fit on the test set

```{r}
yhat = predict(tree.opioid, newdata=opioid[-train,])
opioid.test = opioid[-train,"PRLMISAB"]

plot(yhat, opioid.test)
abline(0,1)
mean((yhat-opioid.test)^2)
```






# Model 5. RANDOM FORESTS REGRESSION 
* Use importance() function to determine which features are important. 
* Parameter `mtry` is number of variables considered at each split. 
* Plot feature importance as percent of MSE, and Increase in Node purity

```{r}
library(randomForest)
rf.opioid = randomForest(PRLMISAB~., data=opioid, subset=train, mtry=3, importance=TRUE)
yhat.rf = predict(rf.opioid, newdata=opioid[-train,])

mean((yhat.rf-opioid.test)^2)
importance(rf.opioid)
varImpPlot(rf.opioid)

plot(yhat.rf, opioid.test)
abline(0,1)
```


## Model 6. BOOSTED TREES
* Boosting builds many smaller trees 
* Each new tree tries to patch up deficiencies of current ensemble of trees. 
* Boosting grows smaller, stubbier trees, and goes after bias. 

Import gbm package ("Gradient Boosted Machines", Friedman) 
* Call gbm, "gaussian distribution", 10000 shallow trees, 
* with shrinkage parameters=0.01, and interaction depth of 4 splits
```{r}
library(gbm)
boost.opioid = gbm(PRLMISAB~., data=opioid[train,], distribution="gaussian", n.trees=10000, shrinkage=0.01, interaction.depth=4)
summary(boost.opioid)
```