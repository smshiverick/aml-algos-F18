Download


Source

PDF
Actions

   Copy Project
   Word Count
Sync

   Dropbox
   GitHub
   Mendeley
Settings

Compiler

Main document

Spell check

Auto-complete

Auto-close Brackets

Code check

Editor theme

Overall theme

Keybindings

Font Size

Font Family

Line Height

PDF Viewer

Hotkeys

   Show Hotkeys
Menu
AML-pred-models
Review
Share
Submit
History
Chat
 format
 images
 Figure1.pdf
 Figure2.pdf
 Figure3.pdf
 Figure4.pdf
 Figure5.pdf
 Figure6.pdf
 Figure9.pdf
 template
 ACM-Reference-Format.bst
 acmart.cls
 bibtex-error.tex
 bin.tex
 issues.tex
 Makefile
 paper1.tex
 paper2.tex
 report.bib
 report.tex
Editor mode.SourceRich Text

488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Training and Test Set Accuracy}
In constructing and evaluating predictive models it is important to select 
a model that performs well not only with the data used to train the model, 
but also with new observations. A standard practice is to divide the sample 
data into a \emph{training set} and a \emph{testing set} of observations that 
is set aside and used to evaluate model performance. By convention, approximately 
70 to 80 percent of observations are used in the training set and the remaining 
portion is held in the testing set. Two main problems can occur in evaluating 
model performance: overfitting and underfitting. In the case of 
\emph{overfitting}, A model can have high accuracy on the training set 
but perform poorly with new data in the test set because the model is 
`over-fit' to the training data. By contrast, a model can attain high 
accuracy with the test set, while performing poorly with the training data 
because of \emph{underfitting}. One of the simplest classification models, 
K-Nearest neighbors provides an illustrative example. KNN classifies 
observations by assigning the label that is most frequent among the `k' 
number of nearest training samples (k is a parameter selected by the user). 
The accuracy of the KNN classifier for the training set and testing set is 
plotted as a function of the parameter k-neighbors in Figure 2. The plot 
shows that increased accuracy on the testing set is associated with 
decreased training set accuracy, and conversely, increase accuracy on 
the training set is related to decreased test set accuracy. The best model 
optimizes test set accuracy while strikes a balance between the problems of 
overfitting and underfitting. In the case of KNN, performance on the test set 
increased only slightly between 2 and 4 neighbors, but did not improve much 
beyond 5 neighbors. Therefore, a model with k=4 neighbors provides a 
reasonable solution for the data. 
\subsubsection{Imbalanced Classes}
Previous studies have analyzed the misuse and abuse of prescription opioids
(MUPO) using logistic regression and identified factors that influence MUPO 
such as gender and mental illness \cite{rice12, unick13, jones15, mccabe12}. 
The present study extends previous work by comparing the performance of ten 
classifier models of pain reliever misuse and abuse and evaluating each model 
  Recompile
13
Full screen
